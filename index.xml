<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>A blog</title>
    <link>/</link>
    <description>Recent content on A blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>manthanrsheth96@gmail.com (Manthan-R-Sheth)</managingEditor>
    <webMaster>manthanrsheth96@gmail.com (Manthan-R-Sheth)</webMaster>
    <lastBuildDate>Wed, 23 Mar 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Project NAINA</title>
      <link>/2016/03/23/project-naina/</link>
      <pubDate>Wed, 23 Mar 2016 00:00:00 +0000</pubDate>
      <author>manthanrsheth96@gmail.com (Manthan-R-Sheth)</author>
      <guid>/2016/03/23/project-naina/</guid>
      <description>

&lt;p&gt;It stands for :- New Artificial Intelligence with Natural Augmentation.&lt;/p&gt;

&lt;p&gt;The aim of the project was to make a cardboard app in which 3-D drawing could be done. This idea can then be extended to allow 3-D modelling of robots and other structures.&lt;/p&gt;

&lt;h2 id=&#34;tracking-the-users-s-hand-motion&#34;&gt;Tracking the users&amp;rsquo;s hand motion.&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Technology used :&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;kbd&gt;IMU 6050&lt;/kbd&gt; along with Arduino UNO.
Difficulty in transferring the data obtained to the cardboard android app made me drop the idea of using the sensor.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;kbd&gt;Android Acelerometer&lt;/kbd&gt; and Gyroscope data.
The data provided by android&amp;rsquo;s built in sensors is highly sensitive and callibrating it becomes very difficult. Double integrating it to obtain the distance co-ordinates is not possible as it leads to highly errornous data. This made me drop ths idea too.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Solution :&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Finally I made use of the concept of&lt;kbd&gt;Stereographic Vision&lt;/kbd&gt;to overcome the problem.
Two webcams separated by a known distance can be appropiately used to get the exact 3 dimensional co-ordinates a point in space.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;more-to-the-idea-of-stereographic-vision&#34;&gt;&lt;strong&gt;More to the idea of Stereographic Vision.&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;The concept is exactly what our eyes use to see things around us. Each webcam corresponding to each eye. Each webcam produces its own image of the same point in space. Trigonometric relations can then be used to get the exact space co-ordinates of the point.&lt;/p&gt;

&lt;h4 id=&#34;determing-a-point-corresponding-to-user-s-hand&#34;&gt;&lt;strong&gt;Determing a point corresponding to user&amp;rsquo;s hand.&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Having figured out how to get the co-ordinates of the point in space, getting a point corresponding to the user&amp;rsquo;s hand was the next task.&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;I used Image Processing for overcoming the task.&lt;/li&gt;
&lt;li&gt;Tracking a particular colour was the intial approach but background noises of the same colour were the major source of challenge.&lt;/li&gt;
&lt;li&gt;Then the simple concept of luminous body was applied. A luminous body appears white to the webcam irrespective of anything else. So I pasted red coloured cellophane paper to the webcam to filter the actual white colour.&lt;/li&gt;
&lt;li&gt;The only white colour seen by the webcams would be due to the luminous object and nothing else. (white colour would appear red to the webcams because of the cellophane filter).&lt;/li&gt;
&lt;li&gt;OpenCV for JAVA was used to get the white object whose mean was then calculated to obtain a point.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Yipeeee!!!!! Hurdle 1 solved!!! :D&lt;/p&gt;

&lt;h2 id=&#34;transmission-medium&#34;&gt;Transmission Medium&lt;/h2&gt;

&lt;p&gt;Though not an issue but worth mentioning as it was a part of the project.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Two ways that could be used for the purpose were :-&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Involving a third party server like a Python or NodeJS server.&lt;/li&gt;
&lt;li&gt;Using Sockets - Server and Client Sockets.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;rendering-the-lines-from-the-co-ordinates-obtained&#34;&gt;Rendering the lines from the co-ordinates obtained.&lt;/h2&gt;

&lt;p&gt;Once the co-ordinates are obtained from one of the above methods, the next and final task was to plot it in the cardboard android app.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Unity - A lucrative Choice!!&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Unity engine seemed a lucrative choice and it definitely made plotting easiar. But in the course if using it, two probably unsolvable issues arose.&lt;/li&gt;
&lt;li&gt;Unity doesn&amp;rsquo;t have the support for sockets. Third party libs like Unity Photon Network Lib need to be used. In my case the use of third party server was the solution. But&amp;hellip;..&lt;/li&gt;
&lt;li&gt;The Line Renderer in Unity which is used to draw lines between points works incorrectly when you want to draw discrete figures. Line Renderer draws lines continuously making the 3D drawing erronous in my case.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;After a great deal of research on this&amp;hellip;&amp;hellip; finally figured a way out!!!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;OpenGL to the rescue!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I decided to shift from unity to OpenGL for android.
 This solved both my problems. I could use sockets as well as could draw discrete figures using OpenGL.
 The concept I used was to draw cubes with the co-ordinates obtained as the center of the cube. Keeping the size of the cubes quite small, series of cubes appeared like a continuous line.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ahh!!! Work done!!!!&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;To sum it up, Project NAINA involved a wide dimension of technologies that was used to make it a successful product. At the end of the project, the user  (with a torch in his hand and in the field of view of the webcams) could move the torch and draw any pattern. This pattern could be seen in the in app running in the Virtual Reality Kit which made the user feel that he was drawing in a wide 3D space.
The idea could be extended to work wonders!!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>manthanrsheth96@gmail.com (Manthan-R-Sheth)</author>
      <guid>/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>